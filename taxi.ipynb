{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Imports and Global Variables \"\"\"\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import spacy\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from colorama import init\n",
    "\n",
    "# Initialize colorama\n",
    "ERROR = \"\\033[5;91m\"\n",
    "WARNING = \"\\033[5;93m\"\n",
    "SUCCESS = \"\\033[92m\"\n",
    "LABEL = \"\\033[94m\"\n",
    "INFO = \"\\033[97m\"\n",
    "RESET = \"\\033[0m\"\n",
    "init()\n",
    "\n",
    "# Set pandas option\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# Define global variables\n",
    "DATASET_PATH = \"./dataset/\"\n",
    "TRAINER_PATH = \"./trainer/\"\n",
    "\n",
    "INPUT_PATH = \"./data/input/\"\n",
    "MODEL_PATH = \"./data/models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend(list: list, item: str) -> list:\n",
    "    \"\"\"\n",
    "    Utility method to safely append an item into a list\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    list: list\n",
    "        List containing a set of items\n",
    "    item: str\n",
    "        String that needs to be appended to the list\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    list\n",
    "        Original list with the appended item\n",
    "    \"\"\"\n",
    "\n",
    "    if pd.isna(item) | (str(item) == 'nan'):\n",
    "        return list\n",
    "    else:\n",
    "        list.append(item)\n",
    "        return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_address(address: str) -> str:\n",
    "    \"\"\"\n",
    "    Strips the address string of unnecessary symbols and properly formats\n",
    "    the address into a csv file style format using regex\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    address: str\n",
    "        String containing the address\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    str\n",
    "        Properly formatted address string\n",
    "    \"\"\"\n",
    "\n",
    "    stripped = re.sub(r\"(,)(?!\\s)\", \", \", address)\n",
    "    stripped = re.sub(r\"(\\\\n)\", \", \", stripped)\n",
    "    stripped = re.sub(r\"(?!\\s)(-)(?!\\s)\", \" - \", stripped)\n",
    "    stripped = re.sub(r\"\\.\", \"\", stripped)\n",
    "    return stripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def address_span(address: str = None, component: str = None, label: str = None) -> tuple:\n",
    "    \"\"\"\n",
    "    Return a tuple containing the span of the address component in the\n",
    "    address string and the classification label of the component\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    address: str\n",
    "        String containing the address\n",
    "    component: str\n",
    "        String containing the address component\n",
    "    label: str\n",
    "        String containing the classification label of the address component\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    tuple\n",
    "        Tuple of the span of the address component and the classification label\n",
    "    \"\"\"\n",
    "\n",
    "    if pd.isna(component) | (str(component) == 'nan'):\n",
    "        pass\n",
    "    else:\n",
    "        component = re.sub(\"\\.\", \"\", component)\n",
    "        component = re.sub(r\"(?!\\s)(-)(?!\\s)\", \" - \", component)\n",
    "        span = re.search(\"\\\\b(?:\" + component + \")\\\\b\", address)\n",
    "        return (span.start(), span.end(), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_entity_spans(dataset: pd.core.frame.DataFrame, tags: list) -> pd.core.series.Series:\n",
    "    \"\"\"\n",
    "    Create a pandas Series with entity spans for the training dataset\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset: pandas.core.frame.DataFrame\n",
    "        pandas DataFrame containing the training dataset\n",
    "    tags: list\n",
    "        List of data tags\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    pandas.core.series.Series\n",
    "        pandas Series of training dataset entity spans\n",
    "    \"\"\"\n",
    "\n",
    "    dataset[\"Address\"] = dataset[\"Address\"].apply(lambda address: strip_address(address))\n",
    "    dataset[\"Recipient\"] = dataset.apply(lambda row: address_span(address=row['Address'], component=row['Recipient'], label='RECIPIENT'), axis=1)\n",
    "    dataset[\"Building_Name\"] = dataset.apply(lambda row: address_span(address=row['Address'], component=row['Building_Name'], label='BUILDING_NAME'), axis=1)\n",
    "    dataset[\"Building_Number\"] = dataset.apply(lambda row: address_span(address=row['Address'], component=row['Building_Number'], label='BUILDING_NUMBER'), axis=1)\n",
    "    dataset[\"Street\"] = dataset.apply(lambda row: address_span(address=row['Address'], component=row['Street_Name'], label='STREET'), axis=1)\n",
    "    dataset[\"City\"] = dataset.apply(lambda row: address_span(address=row['Address'], component=row['City'], label='CITY'), axis=1)\n",
    "    dataset[\"State\"] = dataset.apply(lambda row: address_span(address=row['Address'], component=row['State'], label='STATE'), axis=1)\n",
    "    dataset[\"Zip_Code\"] = dataset.apply(lambda row: address_span(address=row['Address'], component=row['Zip_Code'], label='ZIP_CODE'), axis=1)\n",
    "    dataset[\"Country\"] = dataset.apply(lambda row: address_span(address=row['Address'], component=row['Country'], label='COUNTRY'), axis=1)\n",
    "    dataset[\"EmptySpan\"] = dataset.apply(lambda x: [], axis=1)\n",
    "\n",
    "    for tag in tags:\n",
    "        dataset[\"EntitySpans\"] = dataset.apply(lambda row: extend(row[\"EmptySpan\"], row[tag]), axis=1)\n",
    "        dataset[\"EntitySpans\"] = dataset[[\"EntitySpans\", \"Address\"]].apply(lambda entity: (entity[1], entity[0]), axis=1)\n",
    "    return dataset[\"EntitySpans\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_docbin(data: list, NLP: spacy.Language) -> spacy.tokens._serialize.DocBin:\n",
    "    \"\"\"\n",
    "    Return a DocBin (ie. serialization of information) used by spaCy\n",
    "    as a training set, using training data and an empty spaCy English model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: list\n",
    "        List containing training data\n",
    "    NLP: spacy.Language\n",
    "        An empty English spaCy model\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    spacy.tokens._serialize.DocBin\n",
    "        DocBin object for building a training set\n",
    "    \"\"\"\n",
    "\n",
    "    docbin = spacy.tokens.DocBin()\n",
    "    for text, annotations in data:\n",
    "        doc = NLP(text)\n",
    "        ents = []\n",
    "        for start, end, label in annotations:\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            if span:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        docbin.add(doc)\n",
    "    return docbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_address(nlp: spacy.Language, address: str) -> list:\n",
    "    \"\"\"\n",
    "    Parses the passed address string and returns the address components\n",
    "    as a list of tuples\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    NLP: spacy.Language\n",
    "        An empty English spaCy model\n",
    "    address: str\n",
    "        String containing the address\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    List\n",
    "        List of address components\n",
    "    \"\"\"\n",
    "\n",
    "    doc = nlp(strip_address(address))\n",
    "    entities = [(entity.text, entity.label_) for entity in doc.ents]\n",
    "\n",
    "    print(f\"{LABEL}Address: {INFO}{address[0:-1]}{RESET}\")\n",
    "    for entity in entities:\n",
    "        print(f\"  {LABEL}{entity[1]}: {INFO}{entity[0]}{RESET}\")\n",
    "    print(\"\")\n",
    "\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Create NLP model and initialize dataframe \"\"\"\n",
    "NLP = spacy.blank('en')\n",
    "\n",
    "DATASET = None\n",
    "if os.path.isfile(DATASET_PATH):\n",
    "    try:\n",
    "        DATASET = pd.read_csv(filepath_or_buffer=DATASET_PATH, sep=\",\", dtype=str)\n",
    "    except Exception:\n",
    "        print(f\"{ERROR}✘ Dataset not found\\n{RESET}\")\n",
    "        exit\n",
    "else:\n",
    "    DATASETS = glob.glob(f\"{DATASET_PATH}/*.csv\")\n",
    "    print(f\"{INFO}Found {len(DATASETS)} datasets{RESET}\")\n",
    "\n",
    "    for dataset in DATASETS:\n",
    "        try:\n",
    "            if DATASET is None:\n",
    "                DATASET = pd.read_csv(filepath_or_buffer=dataset, sep=\",\", dtype=str)\n",
    "            else:\n",
    "                pd.concat([DATASET, pd.read_csv(filepath_or_buffer=dataset, sep=\",\", dtype=str)])\n",
    "        except Exception:\n",
    "            print(f\"{ERROR}✘ Dataset not found{RESET}\")\n",
    "            exit\n",
    "\n",
    "print(f\"{SUCCESS}✔ Successfully loaded dataset(s){RESET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Create entity spans and save to file \"\"\"\n",
    "try:\n",
    "    TAGS = [\"Recipient\", \"Building_Name\", \"Building_Number\", \"Street\", \"City\", \"State\", \"Zip_Code\", \"Country\"]\n",
    "    SPANS = create_entity_spans(DATASET.astype(str), TAGS)\n",
    "    TRAINING_DATA = SPANS.tolist()\n",
    "    print(f\"{SUCCESS}✔ Successfully created entity spans{RESET}\")\n",
    "except Exception:\n",
    "    print(f\"{ERROR}✘ Failed to create entity spans{RESET}\")\n",
    "    exit\n",
    "    \n",
    "try:\n",
    "    if os.path.isdir(TRAINER_PATH):\n",
    "        TRAINER_PATH = os.path.join(TRAINER_PATH, \"training.spacy\")    \n",
    "    DOCBIN = create_docbin(TRAINING_DATA, NLP)\n",
    "    DOCBIN.to_disk(TRAINER_PATH)\n",
    "    print(f\"{SUCCESS}✔ Successfully created training set{RESET}\")\n",
    "except Exception:\n",
    "    print(f\"{ERROR}✘ Failed to create training set{RESET}\")\n",
    "    exit\n",
    "\n",
    "print(f\"{INFO} Ready to start training{RESET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Build config and train model \"\"\"\n",
    "try:\n",
    "    command = \"python -m spacy init fill-config \\\"config/base.cfg\\\" \\\"config/config.cfg\\\"\"\n",
    "    print(f\"{INFO} Running command: {command}\")\n",
    "    process = subprocess.Popen(command.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "\n",
    "    command = f\"python -m spacy train \\\"config/config.cfg\\\" --output {MODEL_PATH} --paths.train {TRAINER_PATH} --paths.dev {TRAINER_PATH}\"\n",
    "    print(f\"{INFO} Running command: {command}\")\n",
    "    process = subprocess.Popen(command.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    print(f\"{SUCCESS}✔ Successfully trained model{RESET}\")\n",
    "except Exception as e:\n",
    "    print(f\"{ERROR}✘ Failed to train model{RESET}\")\n",
    "    exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Use trained model to parse address \"\"\"\n",
    "NLP = spacy.load(f\"{MODEL_PATH}/model-best\")\n",
    "print(f\"{SUCCESS}✔ Successfully loaded model{RESET}\")\n",
    "\n",
    "CONTENT = []\n",
    "if os.path.isfile(INPUT_PATH):\n",
    "    try:\n",
    "        FILE = open(INPUT_PATH, \"r\")\n",
    "        CONTENT = FILE.readlines()\n",
    "        FILE.close()\n",
    "        print(f\"{SUCCESS}✔ Successfully loaded input file{RESET}\")\n",
    "    except Exception:\n",
    "        print(f\"{ERROR}✘ Failed to load input file{RESET}\")\n",
    "        exit\n",
    "else:\n",
    "    FILES = next(os.walk(INPUT_PATH), (None, None, []))[2]\n",
    "    for file in FILES:\n",
    "        try:\n",
    "            PATH = f\"{INPUT_PATH}/{file}\"\n",
    "            DATA = open(PATH, \"r\")\n",
    "            CONTENT.append(DATA.readlines())\n",
    "            DATA.close()\n",
    "        except Exception:\n",
    "            print(f\"{ERROR}✘ Failed to load input file{RESET}\")\n",
    "            exit\n",
    "    print(f\"{SUCCESS}✔ Successfully loaded input\\n{RESET}\")\n",
    "\n",
    "for itr in range(len(CONTENT)):\n",
    "    if \"<?xml\" not in CONTENT[itr][0]:\n",
    "        continue\n",
    "    else:\n",
    "        for step in range(len(CONTENT[itr])):\n",
    "            if \"<string>\" not in CONTENT[itr][step]:\n",
    "                CONTENT[itr][step] = CONTENT[itr][step].replace(CONTENT[itr][step], \"\")\n",
    "            else:\n",
    "                CONTENT[itr][step] = CONTENT[itr][step].split(\"<string>\")[1].split(\"</string>\")[0]\n",
    "\n",
    "for FILE in CONTENT:\n",
    "    for ADDREESS in FILE:\n",
    "        if len(ADDREESS) > 0:\n",
    "            try:\n",
    "                parse_address(NLP, ADDREESS)\n",
    "            except Exception:\n",
    "                print(f\"{ERROR}✘ Failed to parse address{RESET}\")\n",
    "                exit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9635acf994ea8de9785e819ee18815d62912e2327679db2043b20e4fdc5f8bec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
